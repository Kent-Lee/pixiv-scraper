# Pixiv Scraper

This is my personal project created to download images from [Pixiv](https://www.pixiv.net/) website. The program will grab the highest resolution images, including images in manga, from specified artists to specified download location, both of which can be edited in `info.json` file. In the download location, the program will create and name directories using the artist names, then download images to the corresponding directories. It stores update information for each artist, so it will only download new uploads.

The program uses threads to download images. The number of threads is declared at the beginning of the program; it can be edited based on your preference. With the default value of `24` threads, I am getting around `7 MB/s` download speed.

![alt text](doc/download.gif?raw=true "download")

![alt text](doc/result.png?raw=true "result")

## Instructions

1. install [Python 3.6+](https://www.python.org/)

2. install library `requests` and [PixivPy](https://github.com/upbit/pixivpy)

        pip install --user requests pixivpy

3. edit `info.json` file

    - `author_ids`: the artist id shown in URL

    - `download_location`: the download directory path

    - `update_info`: contains the last visited image id for each artist. The information will be generated by the program to track update, so ignore this field. Only edit this if you want to control the point in which the program stops downloading images from artists

4. go to root directory and run the program

        python pixiv-scraper.py

## Notes

- Pixiv requires users to login in order to see any content, so you need to register an account for this program to work

- if you want to download R-18 images, you need to change `Viewing restriction` in your Pixiv `User settings`

## Challenges

- sometimes the `requests` module will close the program with error `Remote end closed connection without response`. The issue occurs when downloading too many images (~8GB) at once using `api.download` function. I am not sure the exact cause, but it is most likely due to the high amount of requests sent from the same IP address in a short period of time; hence the server closes the connection

  - Solution: use `session` instead of `api.download` to download images. Allow `session.get` to retry in case of `ConnectionError` exception using `HTTPAdapter` and `Retry` packages

## Todo

- refactor code

- add more functionality (e.g. ranking)